# record_mapper.py

## Key Endpoints

1. **List Variables**  

   ```cURL
   GET /api/v1/edc/studies/{studyKey}/variables
   ```

   Returns JSON:

   ```json
   {
     "data": [
       {
         "variableKey": "WEIGHT",
         "variableId": 10300,
         "label": "Patient Weight",
         …
       },
       …
     ],
     "pagination": { … }
   }
   ```

   citeturn0search0

2. **List Records**  

   ```cURL
   GET /api/v1/edc/studies/{studyKey}/records?filter=formId=={formId}[;visitKey=={visitKey}]
   ```

   Returns JSON:

   ```json
   {
     "data": [
       {
         "recordKey": "R123",
         "subjectKey": "S001",
         "formId": 12,
         "visitKey": "V1",
         "recordStatus": "Record Complete",
         "recordData": {
           "WEIGHT": 68.5,
           "HEIGHT": 172,
           …
         },
         "tsCreated": "2025-04-22T14:05:00Z"
       },
       …
     ],
     "pagination": { … }
   }
   ```

   citeturn0search11

---

## Dynamic Mapping Workflow

1. **Fetch variable metadata**  

   ```python
   vars_raw = self._vars._client.get(
     f"/studies/{study_key}/variables",
     params={"page": 0, "size": 1000}
   )["data"]
   # → list of dicts, each with variableKey, label, etc.
   ```

2. **Extract variableKeys**  

   ```python
   variable_keys = [v["variableKey"] for v in vars_raw]
   ```

3. **Fetch records**  

   ```python
   filter_expr = f"formId=={form_id}"
   if visit_key:
       filter_expr += f";visitKey=={visit_key}"
   recs_raw = self._recs._client.get(
     f"/studies/{study_key}/records",
     params={"filter": filter_expr, "page": 0, "size": 1000}
   )["data"]
   ```

4. **Normalize into DataFrame**  
   Use Pandas’ `json_normalize` to flatten both metadata and data:

   ```python
   import pandas as pd
   
   # Flatten top-level record fields + nested recordData
   df = pd.json_normalize(
     recs_raw,
     record_path=None,
     meta=[k for k in recs_raw[0].keys() if k != "recordData"],
     record_prefix="",
     meta_prefix=""
   )
   # json_normalize will create columns like 'recordData.WEIGHT', 'recordData.HEIGHT'
   # Rename them to drop 'recordData.' prefix:
   df = df.rename(columns=lambda c: c.split(".", 1)[1] if c.startswith("recordData.") else c)
   ```

5. **Ensure all variables appear**  
   If some records lack certain keys, Pandas will fill with NaN. To guarantee every variable column exists:

   ```python
   for vk in variable_keys:
       if vk not in df:
           df[vk] = pd.NA
   ```

6. **Reorder columns**  
   Bring metadata first, then variables in the original form order:

   ```python
   meta_cols = ["recordKey", "subjectKey", "visitKey", "recordStatus", "tsCreated"]
   df = df[meta_cols + variable_keys]
   ```

7. **Attach variable labels (optional)**  
   If you want human‐readable column names, map via `vars_raw`:

   ```python
   label_map = {v["variableKey"]: v.get("label", v["variableKey"]) for v in vars_raw}
   df = df.rename(columns=label_map)
   ```

8. **Return**  

   ```python
   return df
   ```

---

### Why This is Fully Dynamic

- **Variable discovery**: Always fetches the up‐to‐date list of variables for the study/form.  
- **JSON flattening**: `pd.json_normalize` handles any number of keys in `recordData`.  
- **Column guarantees**: We insert missing columns to keep shape consistent across records.  
- **Label mapping**: Easily apply human‐readable headers if you prefer.

Drop this into your `RecordMapper.dataframe` method—no per‐variable `row[v.variableKey] = …` loops needed, and it works out-of-the-box for **any** studyKey/formId combination you configure.
